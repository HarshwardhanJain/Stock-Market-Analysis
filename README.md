# ğŸ“Š Stock Market Analysis using Hive and Hadoop

This project demonstrates how **Apache Hive** can be used over **Hadoop HDFS** to analyze large-scale stock market data and present the insights on a modern **React + Tailwind CSS** dashboard.

---

## ğŸ›  Tools & Technologies

- **Apache Hadoop (v3.3.x)** â€“ for distributed storage via HDFS  
- **Apache Hive (v3.1.x)** â€“ SQL-like query engine on Hadoop  
- **Django + REST Framework** â€“ backend to serve Hive query outputs  
- **ReactJS + Tailwind CSS** â€“ interactive frontend dashboard  
- **HiveQL** â€“ for performing analytical queries  
- **HDFS** â€“ for storing large CSV-based datasets  
- **Manual Hive View** â€“ for exporting Hive query results

---

## ğŸ“ Dataset Description

### StockPrices.csv

- **Fields:** `stock_id`, `date`, `open_price`, `close_price`, `high_price`, `low_price`, `volume`  
- **Size:** 50 MB  
- **Records:** 851,265  

### StockCompanies.csv

- **Fields:** `stock_id`, `company_name`, `sector`, `industry`  
- **Size:** 40 KB  
- **Records:** 509  

These datasets are linked via the `stock_id` field and stored in HDFS.

---

## ğŸ”§ Setup Instructions

### 1. Upload Data to HDFS

```bash
hadoop fs -mkdir /user/hive/warehouse/stock_data
hadoop fs -put StockPrices.csv /user/hive/warehouse/stock_data/
hadoop fs -put StockCompanies.csv /user/hive/warehouse/stock_data/
```

### 2. Create Hive Tables

```sql
CREATE TABLE stock_prices (
  stock_id STRING,
  date STRING,
  open_price FLOAT,
  close_price FLOAT,
  high_price FLOAT,
  low_price FLOAT,
  volume INT
) ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

LOAD DATA INPATH '/user/hive/warehouse/stock_data/StockPrices.csv'
INTO TABLE stock_prices;

CREATE TABLE stock_companies (
  stock_id STRING,
  company_name STRING,
  sector STRING,
  industry STRING
) ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

LOAD DATA INPATH '/user/hive/warehouse/stock_data/StockCompanies.csv'
INTO TABLE stock_companies;
```

### 3. Run the Backend (Django)

```bash
cd backend
python manage.py runserver
```

- Make sure Hive query `.txt` files, their output `.csv` files, and optional visualization scripts/images are organized under:

```txt
project_data/
  â”œâ”€â”€ 1_Volumne_Based_Queries/
  â”‚    â”œâ”€â”€ VOL_query_sector_daily_volume.txt
  â”‚    â”œâ”€â”€ output/
  â”‚    â”‚   â””â”€â”€ VOL_query_sector_daily_volume.csv
  â”‚    â””â”€â”€ visualization/
  â”‚         â”œâ”€â”€ VOL_query_sector_daily_volume.py
  â”‚         â””â”€â”€ VOL_query_sector_daily_volume.png
  â”œâ”€â”€ 2_CLOSE_Price_&_Percent_Change_Queries/
  â”‚    â”œâ”€â”€ CLOSE_query_percent_change.txt
  â”‚    â””â”€â”€ output/
  â”‚         â””â”€â”€ CLOSE_query_percent_change.csv
  â””â”€â”€ ...
```

These folders and files are read by the Django backend to serve query details and results to the frontend.

### 4. Run the Frontend (React)

```bash
cd frontend
npm install
npm start
```

App will be available at:  
[http://localhost:3000](http://localhost:3000)

---

## ğŸ§­ Navigation Structure

- **Home Page:** Browse by query category  
- **Category Page:** View all Hive `.txt` queries under selected category  
- **Query Viewer Page:** See raw Hive query + output CSV or TXT preview  

---

## âœ¨ Features

- Hive query previews with syntax highlighting  
- Render CSV and TXT output directly in browser  
- Search/filter queries  
- Mobile-friendly Tailwind UI  
- Breadcrumb navigation  
- Fully modular React components  

---

## ğŸš€ Future Enhancements

- Add export/download result feature  
- Enable user login and saved query states  
- Implement ML analysis using Spark MLlib  
- Add Hive partitioning for faster queries  
- Dockerize the backend + frontend  

---

## ğŸ“‚ Project Folder Structure

```txt
Stock Market Analysis/
â”œâ”€â”€ backend/                        # Django backend
â”‚   â”œâ”€â”€ api/                        # API views to serve query/output/plots
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ __pycache__/            # [ignored in .gitignore]
â”‚   â”œâ”€â”€ stocksite/                  # Django project
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ __pycache__/            # [ignored in .gitignore]
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â””â”€â”€ project_data/               # Hive queries, outputs, and visualizations
â”‚       â”œâ”€â”€ 1_Volumne_Based_Queries/
â”‚       â”œâ”€â”€ 2_CLOSE_Price_&_Percent_Change_Queries/
â”‚       â”œâ”€â”€ 3_GAIN_Gainers_&_Losers/
â”‚       â”œâ”€â”€ 4_VOLAT_Volatility_and_Range/
â”‚       â””â”€â”€ 5_META_Company_Metadata/
â”‚           â”œâ”€â”€ *.txt
â”‚           â”œâ”€â”€ output/
â”‚           â””â”€â”€ visualization/
â”‚
â”œâ”€â”€ frontend/                       # React + Tailwind frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ node_modules/              # [ignored in .gitignore]
â”‚
â”œâ”€â”€ datasets/                       # Raw input datasets
â”‚   â”œâ”€â”€ StockPrices.csv
â”‚   â””â”€â”€ Stockcompanies.csv
â”‚
â”œâ”€â”€ documentation/                 # Docs, reports, and references
â”‚   â”œâ”€â”€ Hadoop_and_Hive_code_explanation.docx    # [ignored in .gitignore]
â”‚   â”œâ”€â”€ Stock_Market_Analysis_Report.docx        # [ignored in .gitignore]
â”‚   â”œâ”€â”€ Final Project PPT.pdf
â”‚   â”œâ”€â”€ PPT Slides/
â”‚   â”‚   â””â”€â”€ 12.png
â”‚   â””â”€â”€ Website Screenshots/
â”‚       â””â”€â”€ Average-Closing-Price-by-Sector-Over-Time.png
â”‚
â”œâ”€â”€ .gitignore                     # Git ignore file (see below âš ï¸)
â”œâ”€â”€ README.md
```

---

## âš ï¸ `.gitignore` Rules

Ensure you **do not commit large files or unnecessary build/bytecode directories**. Your `.gitignore` includes:

```txt
Hadoop_and_Hive_code_explanation.docx
Stock_Market_Analysis_Report.docx

backend/api/__pycache__
backend/stocksite/__pycache__

frontend/node_modules
```

---

## ğŸ“„ License & Acknowledgement

This project was developed as part of the **Big Data Lab (CSL311)** course at  
**The NorthCap University, Gurugram**.

**Prepared by:**

- Harshwardhan Jain â€“ 22CSU392  
- Raghav Sharma â€“ 22CSU229  
- Mehul Miglani â€“ 22CSU323  

**Faculty Guide:**  
Aarti Kukreja
